# TOML é…ç½®å•é¡Œå®Œæ•´è§£é‡‹

**ç‚ºä»€éº¼ä¹‹å‰ TOML é…ç½®ä¸€ç›´å‡ºå•é¡Œï¼Ÿç‚ºä»€éº¼å¿…é ˆç”¨ CLIï¼Ÿ**

---

## ğŸ” å•é¡Œæ ¹æº

### Kohya SS çš„å…©ç¨®é…ç½®æ–¹å¼

Kohya SS sd-scripts å¯¦éš›ä¸Šæ”¯æ´**å…©ç¨®ä¸åŒçš„é…ç½®æ–¹å¼**ï¼Œä½†æˆ‘å€‘ä¹‹å‰**æ··æ·†**äº†å®ƒå€‘ï¼š

#### æ–¹å¼ 1: `--dataset_config` (Kohya åŸç”Ÿæ”¯æ´)
```bash
python train_network.py \
    --dataset_config dataset.toml \
    --pretrained_model_name_or_path /path/to/model \
    --output_dir /path/to/output \
    --learning_rate 0.0001 \
    # ... å…¶ä»–æ‰€æœ‰åƒæ•¸éƒ½è¦ç”¨ CLI å‚³é
```

**ç‰¹é»ï¼š**
- âœ… Kohya å®˜æ–¹åŸç”Ÿæ”¯æ´
- âš ï¸  **åªèƒ½é…ç½®æ•¸æ“šé›†éƒ¨åˆ†**ï¼ˆåœ–ç‰‡è·¯å¾‘ã€batch sizeã€resolution ç­‰ï¼‰
- âŒ **ä¸èƒ½é…ç½®è¨“ç·´åƒæ•¸**ï¼ˆlearning rate, optimizer, epochs ç­‰ï¼‰
- âŒ å…¶ä»–åƒæ•¸å¿…é ˆé€šé CLI å‚³é

**dataset.toml å…§å®¹ç¯„ä¾‹ï¼š**
```toml
[general]
shuffle_caption = true
keep_tokens = 3

[[datasets]]
resolution = 512
batch_size = 10

  [[datasets.subsets]]
  image_dir = "/path/to/images"
  class_tokens = "character boy"
  caption_extension = ".txt"
```

#### æ–¹å¼ 2: `--config_file` (å®Œæ•´é…ç½®ï¼Œéƒ¨åˆ†è…³æœ¬æ”¯æ´)
```bash
python train_network.py \
    --config_file full_config.toml
```

**ç‰¹é»ï¼š**
- âš ï¸  **ä¸æ˜¯æ‰€æœ‰ Kohya è…³æœ¬éƒ½æ”¯æ´**
- âœ… å¯ä»¥é…ç½®æ‰€æœ‰è¨“ç·´åƒæ•¸
- âœ… å–®ä¸€æ–‡ä»¶åŒ…å«å®Œæ•´é…ç½®
- âŒ Kohya å®˜æ–¹æ–‡æª”æ²’æœ‰æ˜ç¢ºèªªæ˜æ­¤åŠŸèƒ½

**full_config.toml å…§å®¹ç¯„ä¾‹ï¼š**
```toml
[model_arguments]
pretrained_model_name_or_path = "/path/to/model"
output_dir = "/path/to/output"

[training_arguments]
learning_rate = 0.0001
max_train_epochs = 15

[network_arguments]
network_dim = 64

[dataset_arguments]
dataset_config = "/path/to/dataset.toml"
```

---

## âŒ ç‚ºä»€éº¼ä¹‹å‰å‡ºå•é¡Œï¼Ÿ

### å•é¡Œ 1: æ··æ·†äº†å…©ç¨®é…ç½®æ–¹å¼

æˆ‘å€‘ä¹‹å‰å‰µå»ºçš„ TOML æ–‡ä»¶ä½¿ç”¨äº† **`--config_file` æ ¼å¼**ï¼Œä½†åœ¨ä»£ç¢¼ä¸­ä½¿ç”¨ **`--dataset_config`** åƒæ•¸ï¼Œå°è‡´ï¼š

```python
# éŒ¯èª¤çš„ä½¿ç”¨æ–¹å¼ï¼ˆä¹‹å‰çš„ä»£ç¢¼ï¼‰
cmd = [
    'python', 'train_network.py',
    '--dataset_config', 'full_config.toml',  # âŒ é€™æ˜¯å®Œæ•´é…ç½®æ–‡ä»¶
    # ç¼ºå°‘å…¶ä»–å¿…è¦çš„ CLI åƒæ•¸
]
```

**çµæœï¼š**
- Kohya åªè®€å–äº†æ•¸æ“šé›†é…ç½®éƒ¨åˆ†
- è¨“ç·´åƒæ•¸ï¼ˆlearning rate, optimizer ç­‰ï¼‰æ²’æœ‰è¢«è¨­ç½®
- å°è‡´è¨“ç·´å¤±æ•—æˆ–ä½¿ç”¨é»˜èªå€¼

### å•é¡Œ 2: ä¸æ¸…æ¥š `--config_file` çš„æ”¯æ´ç‹€æ³

```bash
# æª¢æŸ¥ train_network.py æ˜¯å¦æ”¯æ´ --config_file
cd /mnt/c/AI_LLM_projects/kohya_ss/sd-scripts
python train_network.py --help | grep config_file

# çµæœï¼šæ‰¾åˆ°äº† --config_file é¸é …
# --config_file CONFIG_FILE
#                     using .toml instead of args to pass hyperparameter
```

**2024-11-12 æ›´æ–°å¾Œçš„çµè«–ï¼š**
- âœ… `train_network.py` **åŒæ™‚æ”¯æ´** `--config_file` å’Œ `--dataset_config`
- âš ï¸  ä½† `--config_file` çš„ `resolution` åƒæ•¸è§£ææœ‰å•é¡Œ
- âœ… **æ¨è–¦ä½¿ç”¨** `--dataset_config` + CLI åƒæ•¸æ··åˆæ–¹å¼
- âœ… æ›´ç©©å®šã€æ›´éˆæ´»ã€æ›´é©åˆè‡ªå‹•åŒ–è¿­ä»£è¨“ç·´

### å•é¡Œ 3: ä¹‹å‰æ²’æœ‰æ­£ç¢ºçš„ç¯„æœ¬

æˆ‘å€‘ä¹‹å‰çš„ TOML ç¯„æœ¬æ··åˆäº†å…©ç¨®æ ¼å¼ï¼Œå°è‡´æ··äº‚ï¼š

```toml
# éŒ¯èª¤çš„æ··åˆæ ¼å¼
[model_arguments]  # é€™éœ€è¦ --config_file æ”¯æ´
pretrained_model_name_or_path = "..."

[general]  # é€™æ˜¯ --dataset_config æ ¼å¼
shuffle_caption = true
```

---

## âœ… æ­£ç¢ºçš„è§£æ±ºæ–¹æ¡ˆ

### ç•¶å‰çš„ä»£ç¢¼ï¼ˆCLI æ–¹å¼ï¼‰

```python
# scripts/training/iterative_lora_optimizer.py
cmd = [
    'python', 'train_network.py',
    '--dataset_config', dataset_config_path,  # âœ“ åªç”¨æ–¼æ•¸æ“šé›†é…ç½®
    '--pretrained_model_name_or_path', model_path,
    '--output_dir', output_dir,
    '--learning_rate', str(learning_rate),
    '--optimizer_type', 'AdamW',
    '--network_dim', '64',
    # ... æ‰€æœ‰å…¶ä»–åƒæ•¸
]
```

**å„ªé»ï¼š**
- âœ… Kohya å®Œå…¨æ”¯æ´
- âœ… éˆæ´»å‹•æ…‹èª¿æ•´åƒæ•¸
- âœ… é©åˆè‡ªå‹•åŒ–è¿­ä»£è¨“ç·´

**ç¼ºé»ï¼š**
- âŒ å‘½ä»¤è¡Œå¾ˆé•·ï¼ˆ50+ å€‹åƒæ•¸ï¼‰
- âŒ é›£ä»¥æ‰‹å‹•è¼¸å…¥
- âŒ ä¸æ˜“ç‰ˆæœ¬æ§åˆ¶

### âœ… æ¨è–¦æ–¹æ¡ˆï¼šæ··åˆæ–¹å¼ï¼ˆ2024-11-12 æ›´æ–°ï¼‰

**1. æ•¸æ“šé›†é…ç½®ç”¨ TOML**
```toml
# configs/luca_human/dataset.toml
# âš ï¸  æ³¨æ„ï¼šä¸è¦ä½¿ç”¨ [general] å€å¡Šï¼
# 2024-11-12 æ¸¬è©¦ç™¼ç¾ï¼šKohya ä¸æ”¯æ´ [general] å€å¡Š
# shuffle_caption, keep_tokens ç­‰åƒæ•¸æ‡‰è©²åœ¨ subsets å±¤ç´š

[[datasets]]
resolution = 512         # å–®å€‹æ•´æ•¸ï¼Œä¸æ˜¯ [512, 512]
batch_size = 8
enable_bucket = true
min_bucket_reso = 384
max_bucket_reso = 768
bucket_reso_steps = 64
bucket_no_upscale = false

  [[datasets.subsets]]
  image_dir = "/path/to/images"
  num_repeats = 1
  shuffle_caption = true      # âœ… åœ¨é€™è£¡ï¼
  keep_tokens = 3             # âœ… åœ¨é€™è£¡ï¼
  caption_extension = ".txt"  # âœ… åœ¨é€™è£¡ï¼
  color_aug = false
  flip_aug = false
```

**2. è¨“ç·´åƒæ•¸ç”¨è…³æœ¬é…ç½®**
```python
# scripts/training/train_luca.py
training_config = {
    'pretrained_model_name_or_path': '/path/to/model',
    'output_dir': '/path/to/output',
    'learning_rate': 0.0001,
    'optimizer_type': 'AdamW8bit',
    'network_dim': 64,
    'network_alpha': 32,
    'max_train_epochs': 15,
    # ... æ‰€æœ‰è¨“ç·´åƒæ•¸
}

cmd = [
    'conda', 'run', '-n', 'kohya_ss',
    'python', '/path/to/train_network.py',
    '--dataset_config', 'configs/luca_human/dataset.toml',
]

# æ·»åŠ æ‰€æœ‰è¨“ç·´åƒæ•¸
for key, value in training_config.items():
    cmd.extend([f'--{key}', str(value)])

subprocess.run(cmd)
```

**3. æˆ–è€…å‰µå»ºåŒ…è£è…³æœ¬**
```python
# scripts/training/launch_with_config.py
import toml
import subprocess

def load_full_config(config_path):
    """å¾å®Œæ•´ TOML é…ç½®åŠ è¼‰æ‰€æœ‰åƒæ•¸"""
    config = toml.load(config_path)

    cmd = ['conda', 'run', '-n', 'kohya_ss', 'python', 'train_network.py']

    # å¾ [model_arguments] æ·»åŠ åƒæ•¸
    for key, value in config.get('model_arguments', {}).items():
        cmd.extend([f'--{key}', str(value)])

    # å¾ [training_arguments] æ·»åŠ åƒæ•¸
    for key, value in config.get('training_arguments', {}).items():
        cmd.extend([f'--{key}', str(value)])

    # ... è™•ç†å…¶ä»–å€æ®µ

    return cmd

# ä½¿ç”¨
config_path = 'configs/luca_human/full_config.toml'
cmd = load_full_config(config_path)
subprocess.run(cmd)
```

---

## ğŸ“Š ä¸‰ç¨®æ–¹å¼å°æ¯”

| æ–¹å¼ | å„ªé» | ç¼ºé» | é©ç”¨å ´æ™¯ |
|------|------|------|----------|
| **ç´” CLI** | â€¢ Kohya å®Œå…¨æ”¯æ´<br>â€¢ éˆæ´»å‹•æ…‹èª¿æ•´ | â€¢ å‘½ä»¤è¡Œè¶…é•·<br>â€¢ é›£ä»¥ç®¡ç† | è‡ªå‹•åŒ–ç³»çµ±ã€è…³æœ¬æ§åˆ¶ |
| **dataset_config + CLI** | â€¢ æ•¸æ“šé›†é…ç½®æ¸…æ™°<br>â€¢ è¨“ç·´åƒæ•¸éˆæ´» | â€¢ ä»éœ€å¤§é‡ CLI åƒæ•¸ | **æ¨è–¦ï¼šä¸€èˆ¬ä½¿ç”¨** |
| **å®Œæ•´ TOML + åŒ…è£å™¨** | â€¢ é…ç½®çµ±ä¸€ç®¡ç†<br>â€¢ æ˜“æ–¼ç‰ˆæœ¬æ§åˆ¶ | â€¢ éœ€è¦è‡ªå®šç¾©åŒ…è£å™¨<br>â€¢ é¡å¤–ç¶­è­·æˆæœ¬ | å›ºå®šé…ç½®ã€åœ˜éšŠå”ä½œ |

---

## ğŸ¯ æˆ‘å€‘çš„ç¯„æœ¬å¦‚ä½•ä½¿ç”¨

### ç¯„æœ¬æ–‡ä»¶çµæ§‹

```
configs/templates/
â”œâ”€â”€ lora_training_template.toml      # å®Œæ•´é…ç½®ç¯„æœ¬ï¼ˆéœ€åŒ…è£å™¨ï¼‰
â””â”€â”€ dataset_config_template.toml     # æ•¸æ“šé›†é…ç½®ç¯„æœ¬ï¼ˆç›´æ¥ä½¿ç”¨ï¼‰
```

### ä½¿ç”¨æ–¹å¼ Aï¼šæ•¸æ“šé›† TOML + è…³æœ¬åƒæ•¸

```bash
# 1. è¤‡è£½æ•¸æ“šé›†ç¯„æœ¬
cp configs/templates/dataset_config_template.toml configs/my_char/dataset.toml

# 2. ç·¨è¼¯ dataset.tomlï¼ˆåªé…ç½®æ•¸æ“šé›†ï¼‰
nano configs/my_char/dataset.toml

# 3. å‰µå»ºè¨“ç·´è…³æœ¬
cat > train_my_char.sh << 'EOF'
#!/bin/bash
conda run -n kohya_ss python /path/to/train_network.py \
    --dataset_config configs/my_char/dataset.toml \
    --pretrained_model_name_or_path /path/to/model \
    --output_dir /path/to/output \
    --learning_rate 0.0001 \
    --optimizer_type AdamW8bit \
    --network_dim 64 \
    --network_alpha 32 \
    --max_train_epochs 15 \
    --mixed_precision fp16 \
    --gradient_checkpointing \
    --cache_latents \
    --cache_latents_to_disk
EOF

# 4. é‹è¡Œ
bash train_my_char.sh
```

### ä½¿ç”¨æ–¹å¼ Bï¼šå®Œæ•´ TOML + åŒ…è£å™¨ï¼ˆæœªä¾†å¯¦ç¾ï¼‰

```bash
# 1. è¤‡è£½å®Œæ•´é…ç½®ç¯„æœ¬
cp configs/templates/lora_training_template.toml configs/my_char/full_config.toml

# 2. ç·¨è¼¯å®Œæ•´é…ç½®
nano configs/my_char/full_config.toml

# 3. ä½¿ç”¨åŒ…è£å™¨é‹è¡Œ
python scripts/training/launch_with_config.py \
    --config_file configs/my_char/full_config.toml
```

---

## ğŸ’¡ é‡è¦ç™¼ç¾è¨˜éŒ„

### 1. Kohya å®˜æ–¹é…ç½®ç³»çµ±

æ ¹æ“š `/mnt/c/AI_LLM_projects/ai_warehouse/sd-scripts/docs/config_README-en.md`ï¼š

> "This README is about the configuration files that can be passed with the `--dataset_config` option."

**æ˜ç¢ºèªªæ˜ï¼š**
- Kohya å®˜æ–¹åªæ–‡æª”åŒ–äº† `--dataset_config`
- è©²é…ç½®åªç”¨æ–¼æ•¸æ“šé›†è¨­ç½®
- æ²’æœ‰æåˆ°å®Œæ•´çš„ `--config_file` ç³»çµ±

### 2. ç‚ºä»€éº¼æ¸¬è©¦è…³æœ¬å¯ä»¥é‹è¡Œï¼Ÿ

æˆ‘å€‘çš„ `test_toml_training.sh` ä½¿ç”¨ `--config_file` åƒæ•¸ï¼š

```bash
python train_network.py --config_file training_config.toml
```

**å¯èƒ½çš„æƒ…æ³ï¼š**
1. **æŸäº› Kohya è…³æœ¬æ”¯æ´ `--config_file`**ï¼ˆä½†æœªæ–‡æª”åŒ–ï¼‰
2. **éœ€è¦ç‰¹å®šç‰ˆæœ¬çš„ Kohya**
3. **ç¤¾å€è²¢ç»çš„åŠŸèƒ½**ï¼ˆæœªåˆä½µåˆ°ä¸»åˆ†æ”¯ï¼‰

**é©—è­‰æ–¹æ³•ï¼š**
```bash
cd /mnt/c/AI_LLM_projects/ai_warehouse/sd-scripts
python train_network.py --help | grep -A 5 "config_file"

# æˆ–ç›´æ¥æ¸¬è©¦
python train_network.py --config_file test.toml --help
```

### 3. ç•¶å‰è¨“ç·´ç‚ºä½•æˆåŠŸï¼Ÿ

ç•¶å‰çš„ 14 å°æ™‚è¿­ä»£è¨“ç·´ä½¿ç”¨ç´” CLI æ–¹å¼ï¼š

```python
# iterative_lora_optimizer.py ä½¿ç”¨ç´” CLI
cmd = [
    'python', 'train_network.py',
    '--dataset_config', dataset_config_toml,  # åªç”¨æ–¼æ•¸æ“šé›†
    '--pretrained_model_name_or_path', model_path,
    '--output_dir', output_dir,
    '--learning_rate', str(lr),
    # ... 50+ å€‹ CLI åƒæ•¸
]
```

**æˆåŠŸåŸå› ï¼š**
- âœ… ä½¿ç”¨äº† Kohya å®˜æ–¹æ”¯æ´çš„æ–¹å¼
- âœ… `--dataset_config` åªé…ç½®æ•¸æ“šé›†
- âœ… æ‰€æœ‰è¨“ç·´åƒæ•¸é€šé CLI å‚³é
- âœ… æ²’æœ‰ä¾è³´æœªæ–‡æª”åŒ–çš„ `--config_file`

---

## ğŸ“ ç¸½çµèˆ‡å»ºè­°

### å•é¡Œç¸½çµ

1. **æˆ‘å€‘æ··æ·†äº†å…©ç¨®é…ç½®æ–¹å¼**
   - `--dataset_config`ï¼ˆå®˜æ–¹æ”¯æ´ï¼Œåƒ…æ•¸æ“šé›†ï¼‰
   - `--config_file`ï¼ˆå¯èƒ½å­˜åœ¨ï¼Œæœªæ–‡æª”åŒ–ï¼‰

2. **ä¹‹å‰çš„ TOML ç¯„æœ¬æ ¼å¼éŒ¯èª¤**
   - ä½¿ç”¨äº† `[model_arguments]` ç­‰å€æ®µ
   - ä½†ç”¨ `--dataset_config` åƒæ•¸å‚³é
   - Kohya ç„¡æ³•è§£æé€™äº›å€æ®µ

3. **ä¸å¾—ä¸æ”¹ç”¨ CLI**
   - å› ç‚º TOML é…ç½®ç„¡æ³•å·¥ä½œ
   - CLI æ˜¯å”¯ä¸€å¯é çš„æ–¹å¼
   - ä½†å°è‡´å‘½ä»¤è¡Œéé•·ã€é›£ä»¥ç®¡ç†

### ç•¶å‰ç‹€æ…‹

**å·²é©—è­‰å¯ç”¨ï¼š**
- âœ… `--dataset_config` + CLI åƒæ•¸ï¼ˆç•¶å‰ä½¿ç”¨ï¼‰
- âœ… ç´” CLI åƒæ•¸ï¼ˆæ¸¬è©¦é€šéï¼‰
- âœ… kohya_ss ç’°å¢ƒ + AdamW8bitï¼ˆæ¸¬è©¦é€šéï¼‰

**å¾…é©—è­‰ï¼š**
- âš ï¸  `--config_file` æ˜¯å¦çœŸçš„æ”¯æ´ï¼Ÿ
- âš ï¸  æˆ‘å€‘çš„å®Œæ•´ TOML ç¯„æœ¬æ˜¯å¦èƒ½ç”¨ï¼Ÿ
- âš ï¸  éœ€è¦ä»€éº¼ç‰ˆæœ¬çš„ Kohyaï¼Ÿ

### å»ºè­°

**çŸ­æœŸï¼ˆç•¶å‰ä½¿ç”¨ï¼‰ï¼š**
```python
# ä½¿ç”¨ dataset_config + CLI æ··åˆæ–¹å¼
# å„ªé»ï¼šç©©å®šå¯é ã€Kohya å®˜æ–¹æ”¯æ´
# ç¼ºé»ï¼šå‘½ä»¤è¡Œè¼ƒé•·

cmd = [
    'python', 'train_network.py',
    '--dataset_config', 'dataset.toml',  # æ•¸æ“šé›†é…ç½®
    # ... æ‰€æœ‰è¨“ç·´åƒæ•¸ç”¨ CLI
]
```

**ä¸­æœŸï¼ˆåŒ…è£å™¨æ–¹æ¡ˆï¼‰ï¼š**
```python
# å‰µå»º Python åŒ…è£å™¨è®€å–å®Œæ•´ TOML
# å„ªé»ï¼šé…ç½®çµ±ä¸€ã€æ˜“æ–¼ç®¡ç†
# ç¼ºé»ï¼šéœ€è¦ç¶­è­·åŒ…è£å™¨ä»£ç¢¼

def load_full_config(toml_path):
    config = toml.load(toml_path)
    return build_cli_command(config)
```

**é•·æœŸï¼ˆé©—è­‰ä¸¦ä½¿ç”¨ config_fileï¼‰ï¼š**
```bash
# å¦‚æœ --config_file çœŸçš„æ”¯æ´
python train_network.py --config_file full_config.toml
# å„ªé»ï¼šæœ€ç°¡æ½”ã€æœ€æ¨™æº–
# éœ€æ±‚ï¼šé©—è­‰ Kohya ç‰ˆæœ¬å’Œæ”¯æ´æƒ…æ³
```

---

## ğŸ”— ç›¸é—œæ–‡ä»¶

- **Kohya å®˜æ–¹æ–‡æª”:** `/mnt/c/AI_LLM_projects/ai_warehouse/sd-scripts/docs/config_README-en.md`
- **ç•¶å‰ç¯„æœ¬:** `configs/templates/*.toml`
- **ç•¶å‰è¨“ç·´è…³æœ¬:** `scripts/training/iterative_lora_optimizer.py`
- **å®Œæ•´æŒ‡å—:** `docs/KOHYA_TRAINING_GUIDE.md`

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025-11-11
**ç‹€æ…‹ï¼š** å·²è§£æ±º - ä½¿ç”¨ dataset_config + CLI æ··åˆæ–¹å¼
