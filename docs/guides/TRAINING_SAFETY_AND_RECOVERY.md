# è¨“ç·´å®‰å…¨æªæ–½èˆ‡è‡ªå‹•æ¢å¾©æŒ‡å—

**Training Safety Measures & Auto-Recovery Guide**

Created: 2025-11-15
Version: 1.0.0

---

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›å®Œæ•´çš„è¨“ç·´å®‰å…¨æªæ–½ï¼Œé˜²æ­¢é¡ä¼¼ CUDA éŒ¯èª¤ã€è¨“ç·´ä¸­æ–·ç­‰å•é¡Œï¼Œä¸¦æä¾›è‡ªå‹•æ¢å¾©æ©Ÿåˆ¶ã€‚

---

## ğŸ” å¸¸è¦‹å•é¡Œèˆ‡æ ¹æœ¬åŸå› 

### å•é¡Œ 1: CUDA Unknown Error

**ç—‡ç‹€ï¼š**
```
RuntimeError: CUDA error: unknown error
CUDA kernel errors might be asynchronously reported...
```

**æ ¹æœ¬åŸå› ï¼š**
1. **GPU è¨˜æ†¶é«”ç¢ç‰‡åŒ–** â€” é•·æ™‚é–“é‹è¡Œï¼ˆ>6å°æ™‚ï¼‰å°è‡´ VRAM åˆ†é…ç¢ç‰‡åŒ–
2. **Gradient Checkpointing ä¸ç©©å®š** â€” åœ¨æŸäº› PyTorch ç‰ˆæœ¬æˆ– WSL2 ç’°å¢ƒä¸‹ä¸ç©©å®š
3. **WSL2 + CUDA é•·æ™‚é–“é‹è¡Œå•é¡Œ** â€” GPU è™›æ“¬åŒ–å±¤å¯èƒ½ä¸å¦‚åŸç”Ÿç©©å®š
4. **é©…å‹•æˆ–ç¡¬é«”éš¨æ©Ÿå•é¡Œ** â€” å¶ç™¼æ€§éŒ¯èª¤

**é é˜²æªæ–½ï¼š**
- âœ… é—œé–‰ `gradient_checkpointing`ï¼ˆä½¿ç”¨ç©©å®šé…ç½®ï¼‰
- âœ… é™ä½ `gradient_accumulation_steps`ï¼ˆæ¸›å°‘è¨˜æ†¶é«”å£“åŠ›ï¼‰
- âœ… ç¸®çŸ­è¨“ç·´æ™‚é•·ï¼ˆ12 epochs vs 20 epochsï¼‰
- âœ… é »ç¹ä¿å­˜ checkpointï¼ˆæ¯ 2 epochsï¼‰
- âœ… ä½¿ç”¨è‡ªå‹•ç›£æ§å’Œé‡å•Ÿæ©Ÿåˆ¶

---

### å•é¡Œ 2: è¨“ç·´å¡ä½ï¼ˆHangï¼‰

**ç—‡ç‹€ï¼š**
- GPU åˆ©ç”¨ç‡ä½ä½†é€²ç¨‹ä»åœ¨é‹è¡Œ
- é•·æ™‚é–“æ²’æœ‰æ–°çš„ checkpoint ç”¢ç”Ÿ
- æ—¥èªŒè¼¸å‡ºåœæ­¢

**æ ¹æœ¬åŸå› ï¼š**
1. è³‡æ–™è¼‰å…¥å™¨æ­»é–
2. CUDA åŒæ­¥å•é¡Œ
3. I/O é˜»å¡

**é é˜²æªæ–½ï¼š**
- âœ… å•Ÿç”¨æ›èµ·æª¢æ¸¬ï¼ˆ30åˆ†é˜ç„¡é€²åº¦è‡ªå‹•é‡å•Ÿï¼‰
- âœ… ä½¿ç”¨ `num_workers` é©ç•¶å€¼ï¼ˆä¸è¦å¤ªé«˜ï¼‰
- âœ… ç›£æ§ checkpoint æ›´æ–°æ™‚é–“

---

### å•é¡Œ 3: OOM (Out of Memory)

**ç—‡ç‹€ï¼š**
```
RuntimeError: CUDA out of memory
```

**æ ¹æœ¬åŸå› ï¼š**
1. Batch size å¤ªå¤§
2. æ¨¡å‹æˆ–åœ–ç‰‡è§£æåº¦å¤ªé«˜
3. è¨˜æ†¶é«”æ´©æ¼

**é é˜²æªæ–½ï¼š**
- âœ… ä½¿ç”¨ `train_batch_size=1`
- âœ… å•Ÿç”¨ `cache_latents=true`
- âœ… ä½¿ç”¨ 8-bit optimizer
- âœ… ç›£æ§ VRAM ä½¿ç”¨ç‡ï¼ˆè­¦å‘Šé–¾å€¼ 95%ï¼‰

---

## ğŸ›¡ï¸ å®‰å…¨æªæ–½ç³»çµ±æ¶æ§‹

### Layer 1: é…ç½®å„ªåŒ–

**ç©©å®šç‰ˆé…ç½®æ–‡ä»¶ï¼š** `configs/training/sdxl_16gb_stable.toml`

**é—œéµè¨­å®šï¼š**
```toml
# é—œé–‰ gradient checkpointingï¼ˆé¿å… CUDA checkpoint éŒ¯èª¤ï¼‰
gradient_checkpointing = false

# é™ä½ accumulation stepsï¼ˆé™ä½è¨˜æ†¶é«”å£“åŠ›ï¼‰
gradient_accumulation_steps = 4  # å¾ 8 é™åˆ° 4

# ç¸®çŸ­è¨“ç·´æ™‚é•·ï¼ˆé¿å…é•·æ™‚é–“é‹è¡Œå•é¡Œï¼‰
max_train_epochs = 12  # å¾ 20 é™åˆ° 12

# é »ç¹ä¿å­˜ï¼ˆæ–¹ä¾¿æ¢å¾©ï¼‰
save_every_n_epochs = 2
save_last_n_epochs = 3  # ä¿ç•™æœ€å¾Œ 3 å€‹ checkpoints

# 8-bit optimizerï¼ˆçœè¨˜æ†¶é«”ï¼‰
optimizer_type = "AdamW8bit"

# å®Œæ•´ bf16ï¼ˆç©©å®šæ€§ï¼‰
mixed_precision = "bf16"
full_bf16 = true
```

### Layer 2: è‡ªå‹•å¥åº·ç›£æ§

**ç›£æ§è…³æœ¬ï¼š** `scripts/monitoring/training_health_monitor.sh`

**åŠŸèƒ½ï¼š**
- âœ… æ¯ 5 åˆ†é˜æª¢æŸ¥ä¸€æ¬¡ GPU ç‹€æ…‹
- âœ… ç›£æ§æº«åº¦ã€VRAM ä½¿ç”¨ç‡ã€GPU åˆ©ç”¨ç‡
- âœ… åµæ¸¬è¨“ç·´æ›èµ·ï¼ˆ30åˆ†é˜ç„¡é€²åº¦ï¼‰
- âœ… è‡ªå‹•é‡å•Ÿå¤±æ•—çš„è¨“ç·´
- âœ… ç™¼é€æ¡Œé¢é€šçŸ¥ï¼ˆå¦‚æœå¯ç”¨ï¼‰

**ä½¿ç”¨æ–¹å¼ï¼š**
```bash
# åŸºæœ¬ç›£æ§ï¼ˆè‡ªå‹•è·Ÿéš¨ç¾æœ‰ sessionï¼‰
bash scripts/monitoring/training_health_monitor.sh

# æŒ‡å®š session ç›£æ§
bash scripts/monitoring/training_health_monitor.sh \
  --session sdxl_luca_training_safe \
  --output-dir /mnt/data/ai_data/models/lora/luca/sdxl_trial1 \
  --interval 300 \
  --max-restarts 3
```

**ç›£æ§æŒ‡æ¨™ï¼š**
| æŒ‡æ¨™ | é–¾å€¼ | å‹•ä½œ |
|------|------|------|
| GPU æº«åº¦ | >85Â°C | è­¦å‘Š |
| VRAM ä½¿ç”¨ç‡ | >95% | è­¦å‘Š |
| GPU åˆ©ç”¨ç‡ | <5% | æª¢æŸ¥æ›èµ· |
| Checkpoint å¹´é½¡ | >30åˆ†é˜ | é‡å•Ÿè¨“ç·´ |

### Layer 3: è‡ªå‹•é‡å•Ÿæ©Ÿåˆ¶

**é‡å•Ÿè…³æœ¬ï¼š** `scripts/training/safe_restart_training.sh`

**æµç¨‹ï¼š**
1. **æ¸…ç†èˆŠ session** â€” æ®ºæ‰å¡ä½çš„è¨“ç·´é€²ç¨‹
2. **ç­‰å¾… GPU æ¸…ç©º** â€” ç¢ºä¿ VRAM å®Œå…¨é‡‹æ”¾
3. **æª¢æŸ¥ checkpoint** â€” æ‰¾åˆ°æœ€æ–°çš„ checkpoint
4. **é©—è­‰é…ç½®** â€” ç¢ºèªä½¿ç”¨ç©©å®šç‰ˆé…ç½®
5. **å•Ÿå‹•è¨“ç·´** â€” åœ¨æ–° tmux session ä¸­å•Ÿå‹•
6. **å•Ÿå‹•ç›£æ§** â€” è‡ªå‹•å•Ÿå‹•å¥åº·ç›£æ§

**ä½¿ç”¨æ–¹å¼ï¼š**
```bash
# è‡ªå‹•åŒ–é‡å•Ÿï¼ˆå¸¶ç¢ºèªï¼‰
bash scripts/training/safe_restart_training.sh

# æŸ¥çœ‹é‡å•Ÿå¾Œçš„è¨“ç·´
tmux attach -t sdxl_luca_training_safe
```

---

## ğŸ“Š ç›£æ§èˆ‡è¨ºæ–·å·¥å…·

### 1. GPU å¯¦æ™‚ç›£æ§

```bash
# æ¯ 5 ç§’æ›´æ–°ä¸€æ¬¡
watch -n 5 nvidia-smi

# ç°¡åŒ–è¼¸å‡º
watch -n 5 "nvidia-smi --query-gpu=name,memory.used,memory.total,utilization.gpu,temperature.gpu --format=csv"
```

### 2. è¨“ç·´é€²åº¦æª¢æŸ¥

```bash
# æŸ¥çœ‹æœ€æ–° checkpoints
ls -lht /mnt/data/ai_data/models/lora/luca/sdxl_trial1/*.safetensors | head -5

# æŸ¥çœ‹æœ€æ–° sample åœ–ç‰‡
ls -lt /mnt/data/ai_data/models/lora/luca/sdxl_trial1/sample/*.png | head -10

# æª¢æŸ¥ checkpoint å¹´é½¡
stat -c '%y' /mnt/data/ai_data/models/lora/luca/sdxl_trial1/luca_sdxl-*.safetensors | tail -1
```

### 3. Tmux Session ç®¡ç†

```bash
# åˆ—å‡ºæ‰€æœ‰ sessions
tmux ls

# é™„åŠ åˆ°è¨“ç·´ session
tmux attach -t sdxl_luca_training_safe

# é›¢é–‹ sessionï¼ˆä¸çµ‚æ­¢ï¼‰
# æŒ‰ Ctrl+B ç„¶å¾ŒæŒ‰ D

# æ®ºæ‰ session
tmux kill-session -t sdxl_luca_training_safe
```

### 4. æŸ¥çœ‹è¨“ç·´æ—¥èªŒ

```bash
# æŸ¥çœ‹ç›£æ§æ—¥èªŒ
tail -f logs/training_monitor/monitor_*.log

# æŸ¥çœ‹æœ€æ–°çš„ sample ç”Ÿæˆ
ls -lt /mnt/data/ai_data/models/lora/luca/sdxl_trial1/sample/ | head -10
```

---

## ğŸš¨ æ‡‰æ€¥è™•ç†æµç¨‹

### æƒ…æ³ 1: è¨“ç·´å´©æ½°

**ç—‡ç‹€ï¼š** Tmux session ä»åœ¨ï¼Œä½†é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯

**è™•ç†æ­¥é©Ÿï¼š**
1. æª¢æŸ¥éŒ¯èª¤è¨Šæ¯é¡å‹ï¼ˆCUDA error, OOM, etc.ï¼‰
2. æª¢æŸ¥æœ€æ–° checkpoint æ˜¯å¦å·²ä¿å­˜
3. ä½¿ç”¨å®‰å…¨é‡å•Ÿè…³æœ¬é‡å•Ÿï¼š
   ```bash
   bash scripts/training/safe_restart_training.sh
   ```

### æƒ…æ³ 2: è¨“ç·´å¡ä½

**ç—‡ç‹€ï¼š** GPU åˆ©ç”¨ç‡ä½ï¼Œé•·æ™‚é–“ç„¡è¼¸å‡º

**è™•ç†æ­¥é©Ÿï¼š**
1. æª¢æŸ¥ GPU ç‹€æ…‹ï¼š`nvidia-smi`
2. æª¢æŸ¥é€²ç¨‹æ˜¯å¦ä»åœ¨é‹è¡Œï¼š`ps aux | grep sdxl_train`
3. æª¢æŸ¥æœ€å¾Œ checkpoint æ™‚é–“
4. å¦‚æœè¶…é 30 åˆ†é˜ï¼Œæ‰‹å‹•æ®ºæ‰ä¸¦é‡å•Ÿï¼š
   ```bash
   tmux kill-session -t sdxl_luca_training_safe
   bash scripts/training/safe_restart_training.sh
   ```

### æƒ…æ³ 3: OOM éŒ¯èª¤

**ç—‡ç‹€ï¼š** `CUDA out of memory`

**è™•ç†æ­¥é©Ÿï¼š**
1. é€²ä¸€æ­¥é™ä½é…ç½®ï¼š
   ```toml
   gradient_accumulation_steps = 2  # å¾ 4 é™åˆ° 2
   vae_batch_size = 1
   cache_latents_to_disk = true  # ä½¿ç”¨ç£ç¢Ÿå¿«å–
   ```
2. é‡å•Ÿè¨“ç·´

### æƒ…æ³ 4: è‡ªå‹•é‡å•Ÿå¤±æ•—

**ç—‡ç‹€ï¼š** ç›£æ§è…³æœ¬é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸

**è™•ç†æ­¥é©Ÿï¼š**
1. æª¢æŸ¥æ ¹æœ¬å•é¡Œï¼ˆç¡¬é«”ï¼Ÿé©…å‹•ï¼Ÿé…ç½®ï¼Ÿï¼‰
2. æŸ¥çœ‹ç›£æ§æ—¥èªŒï¼š`cat logs/training_monitor/monitor_*.log`
3. æ‰‹å‹•ä»‹å…¥ï¼Œèª¿æ•´é…ç½®å¾Œé‡è©¦

---

## âœ… æœ€ä½³å¯¦è¸æ¸…å–®

### è¨“ç·´å‰

- [ ] ä½¿ç”¨ç©©å®šç‰ˆé…ç½®ï¼ˆ`sdxl_16gb_stable.toml`ï¼‰
- [ ] ç¢ºèªæœ‰è¶³å¤ ç£ç¢Ÿç©ºé–“ï¼ˆæ¯å€‹ checkpoint ~870MBï¼‰
- [ ] æ¸…ç† GPUï¼ˆç„¡å…¶ä»–é€²ç¨‹ï¼‰
- [ ] å•Ÿå‹•å¥åº·ç›£æ§

### è¨“ç·´ä¸­

- [ ] æ¯å°æ™‚æª¢æŸ¥ä¸€æ¬¡ GPU æº«åº¦å’Œ VRAM
- [ ] æ¯ 2-3 å°æ™‚æª¢æŸ¥ checkpoint æ˜¯å¦æ­£å¸¸ä¿å­˜
- [ ] ç›£æ§æ—¥èªŒç„¡ç•°å¸¸éŒ¯èª¤
- [ ] GPU åˆ©ç”¨ç‡ä¿æŒåœ¨ 80-100%

### è¨“ç·´å¾Œ

- [ ] é©—è­‰æ‰€æœ‰ checkpoints å®Œæ•´æ€§
- [ ] ä¿ç•™æœ€å¾Œ 3 å€‹ checkpoints
- [ ] æ¸¬è©¦ checkpoint å“è³ª
- [ ] å‚™ä»½æœ€ä½³ checkpoint

---

## ğŸ“ˆ æ€§èƒ½èˆ‡ç©©å®šæ€§å°æ¯”

| é…ç½®é …ç›® | å„ªåŒ–ç‰ˆ | ç©©å®šç‰ˆ | èªªæ˜ |
|---------|--------|--------|------|
| `gradient_checkpointing` | âœ… true | âŒ false | ç©©å®šç‰ˆé—œé–‰é¿å… CUDA éŒ¯èª¤ |
| `gradient_accumulation_steps` | 8 | 4 | ç©©å®šç‰ˆé™ä½è¨˜æ†¶é«”å£“åŠ› |
| `max_train_epochs` | 20 | 12 | ç©©å®šç‰ˆç¸®çŸ­é¿å…é•·æ™‚é–“å•é¡Œ |
| **VRAM ä½¿ç”¨** | ~14GB | ~12GB | ç©©å®šç‰ˆæ›´ä½ |
| **è¨“ç·´é€Ÿåº¦** | è¼ƒå¿« | è¼ƒæ…¢ | ç©©å®šç‰ˆæ…¢ ~15% |
| **ç©©å®šæ€§** | ä¸­ | é«˜ | ç©©å®šç‰ˆæ›´ä¸æ˜“å´©æ½° |
| **æ¨è–¦ä½¿ç”¨** | çŸ­æ™‚è¨“ç·´ | é•·æ™‚è¨“ç·´ | ç©©å®šç‰ˆé©åˆovernight |

---

## ğŸ”„ å¾èˆŠ Checkpoint æ¢å¾©

å¦‚æœéœ€è¦å¾ä¹‹å‰çš„ checkpoint ç¹¼çºŒè¨“ç·´ï¼š

**æ–¹æ³• 1: æ‰‹å‹•æŒ‡å®š checkpointï¼ˆå¦‚æœæ”¯æŒ resumeï¼‰**
```toml
# åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ 
network_weights = "/path/to/luca_sdxl-000004.safetensors"
```

**æ–¹æ³• 2: å¾ checkpoint é–‹å§‹æ–°è¨“ç·´**
- ä½¿ç”¨ checkpoint ä½œç‚ºåŸºç¤æ¨¡å‹
- é™ä½å­¸ç¿’ç‡ï¼ˆé¿å…ç ´å£å·²è¨“ç·´çš„æ¬Šé‡ï¼‰
- ç¸®çŸ­ epochs

---

## ğŸ“ æ•…éšœæ’é™¤è³‡æº

**æ—¥èªŒä½ç½®ï¼š**
- ç›£æ§æ—¥èªŒï¼š`logs/training_monitor/`
- è¨“ç·´è¼¸å‡ºï¼štmux session å…§
- Checkpointï¼š`/mnt/data/ai_data/models/lora/luca/sdxl_trial1/`

**å¸¸ç”¨å‘½ä»¤ï¼š**
```bash
# å®Œæ•´ç‹€æ…‹æª¢æŸ¥
nvidia-smi
tmux ls
ps aux | grep sdxl_train
ls -lht /mnt/data/ai_data/models/lora/luca/sdxl_trial1/*.safetensors

# å¿«é€Ÿé‡å•Ÿ
bash scripts/training/safe_restart_training.sh

# å•Ÿå‹•ç›£æ§
bash scripts/monitoring/training_health_monitor.sh --session sdxl_luca_training_safe
```

---

## ğŸ¯ æœªä¾†æ”¹é€²è¨ˆåŠƒ

- [ ] å¯¦ä½œ checkpoint è‡ªå‹•æ¯”è¼ƒå’Œå“è³ªè©•ä¼°
- [ ] æ·»åŠ  Telegram/Discord é€šçŸ¥é›†æˆ
- [ ] å¯¦ä½œè¨“ç·´å“è³ªå³æ™‚è©•ä¼°ï¼ˆFID/CLIP scoreï¼‰
- [ ] è‡ªå‹•èª¿æ•´è¶…åƒæ•¸ï¼ˆå‹•æ…‹ learning rateï¼‰
- [ ] å¤š GPU æ”¯æ´å’Œè² è¼‰å¹³è¡¡

---

**ç‰ˆæœ¬æ­·å²ï¼š**
- v1.0.0 (2025-11-15): åˆå§‹ç‰ˆæœ¬ï¼ŒåŒ…å«è‡ªå‹•ç›£æ§å’Œé‡å•Ÿæ©Ÿåˆ¶

**ä½œè€…ï¼š** Claude Code Assistant
**æ›´æ–°ï¼š** 2025-11-15
