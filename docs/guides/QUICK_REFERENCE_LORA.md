# LoRA Training Quick Reference

**å¿«é€Ÿåƒè€ƒæŒ‡å— - é©ç”¨æ–¼æ‰€æœ‰æœªä¾†çš„ LoRA è¨“ç·´**

---

## ðŸš€ å¿«é€Ÿé–‹å§‹ï¼ˆ5 åˆ†é˜è¨­ç½®ï¼‰

### âš ï¸ é‡è¦ï¼šTOML é…ç½®èªªæ˜Ž
**Kohya åªæ”¯æ´ `--dataset_config`ï¼ˆæ•¸æ“šé›†é…ç½®ï¼‰ï¼Œè¨“ç·´åƒæ•¸éœ€ç”¨ CLI æˆ–è…³æœ¬å‚³éžã€‚**
è©³ç´°èªªæ˜Žè¦‹ï¼š`docs/TOML_CONFIG_EXPLAINED.md`

### 1. å•Ÿå‹•å°ˆç”¨ç’°å¢ƒ
```bash
conda activate kohya_ss
```

### 2. å¾žç¯„æœ¬å‰µå»ºæ•¸æ“šé›†é…ç½®
```bash
# å‰µå»ºè§’è‰²ç›®éŒ„
mkdir -p configs/your_character

# è¤‡è£½æ•¸æ“šé›†ç¯„æœ¬ï¼ˆåªéœ€é€™å€‹ï¼‰
cp configs/templates/dataset_config_template.toml configs/your_character/dataset.toml

# ç·¨è¼¯é…ç½®ï¼ˆæ›¿æ›è·¯å¾‘å’Œåƒæ•¸ï¼‰
nano configs/your_character/dataset.toml
```

### 3. å‰µå»ºè¨“ç·´è…³æœ¬
```bash
# å‰µå»ºè¨“ç·´è…³æœ¬ï¼ˆåŒ…å«æ‰€æœ‰è¨“ç·´åƒæ•¸ï¼‰
cat > configs/your_character/train.sh << 'EOF'
#!/bin/bash
conda run -n kohya_ss python /mnt/c/AI_LLM_projects/ai_warehouse/sd-scripts/train_network.py \
    --dataset_config configs/your_character/dataset.toml \
    --pretrained_model_name_or_path /path/to/model \
    --output_dir /path/to/output \
    --learning_rate 0.0001 \
    --optimizer_type AdamW8bit \
    --network_dim 64 \
    --max_train_epochs 15 \
    --mixed_precision fp16 \
    --gradient_checkpointing \
    --cache_latents_to_disk
EOF

chmod +x configs/your_character/train.sh
```

### 4. é–‹å§‹è¨“ç·´
```bash
bash configs/your_character/train.sh
```

---

## âš™ï¸ RTX 5080 æœ€ä½³é…ç½®ï¼ˆè¤‡è£½å³ç”¨ï¼‰

### SD 1.5 - è§’è‰² LoRAï¼ˆ200-400 å¼µåœ–ç‰‡ï¼‰
```toml
[training_arguments]
learning_rate = 0.0001
unet_lr = 0.0001
text_encoder_lr = 0.00005
optimizer_type = "AdamW8bit"  # æˆ– "AdamW"
max_train_epochs = 15
batch_size = 10  # åœ¨ dataset_config.toml ä¸­è¨­ç½®
gradient_accumulation_steps = 2

[network_arguments]
network_dim = 64
network_alpha = 32

[caching_arguments]
cache_latents = true
cache_latents_to_disk = true
```

### SD 1.5 - é¢¨æ ¼ LoRAï¼ˆ500-1000 å¼µåœ–ç‰‡ï¼‰
```toml
[training_arguments]
learning_rate = 0.00005  # è¼ƒä½Ž
max_train_epochs = 10
batch_size = 8

[network_arguments]
network_dim = 128  # è¼ƒé«˜å®¹é‡
network_alpha = 64
```

### â­ SDXL - è§’è‰² LoRAï¼ˆ16GB VRAMå„ªåŒ–ï¼‰
```toml
[model]
pretrained_model_name_or_path = "stabilityai/stable-diffusion-xl-base-1.0"
network_dim = 128
network_alpha = 96

[training_arguments]
# æ ¸å¿ƒ16GBå„ªåŒ–ï¼ˆå¿…é ˆï¼‰
optimizer_type = "AdamW8bit"           # â­ çœ40% VRAM
mixed_precision = "bf16"               # â­ çœ25% VRAM
full_bf16 = true
gradient_checkpointing = true          # â­ çœ30% VRAM
cache_latents = true
vae_batch_size = 1

# å­¸ç¿’çŽ‡ï¼ˆSDXLéœ€è¦è¼ƒä½Žï¼‰
learning_rate = 0.0001                 # SD 1.5çš„77%
text_encoder_lr = 0.00006
unet_lr = 0.0001

# Batchè¨­ç½®
train_batch_size = 1                   # â­ å°batch for VRAM
gradient_accumulation_steps = 8        # â­ ç¶­æŒeffective batch=8

# è¨“ç·´æ™‚é•·
max_train_epochs = 20                  # æ¯”SD 1.5å¤š2-4 epochs
save_every_n_epochs = 2

# SDXLç‰¹æœ‰è¨­ç½®
resolution = "1024,1024"
enable_bucket = true
bucket_no_upscale = true

# ç©©å®šæ€§ï¼ˆèˆ‡SD 1.5ç›¸åŒï¼‰
min_snr_gamma = 5.0
noise_offset = 0.05
lr_scheduler = "cosine_with_restarts"
```

**SDXL vs SD 1.5 å°æ¯”ï¼š**
| é …ç›® | SD 1.5 | SDXL | å‚™è¨» |
|------|--------|------|------|
| **è¨“ç·´æ™‚é–“** | 2-3å°æ™‚ | 5-6å°æ™‚ | 2.5å€ |
| **VRAM** | 10-12GB | 14-15GB | +30% |
| **è§£æžåº¦** | 512px | 1024px | 2å€ç´°ç¯€ |
| **è¦–è¦ºå“è³ª** | â­â­â­ | â­â­â­â­â­ | é¡¯è‘—æå‡ |
| **æª”æ¡ˆå¤§å°** | 140MB | 800MB | 6å€ |

---

## ðŸ“Š VRAM ä½¿ç”¨å°ç…§è¡¨

### SD 1.5
| è§£æžåº¦     | Batch Size | Network Dim | VRAM ä½¿ç”¨ | å»ºè­°å ´æ™¯      |
|-----------|------------|-------------|-----------|--------------|
| 512Ã—512   | 10         | 64          | ~15GB     | è§’è‰² LoRA     |
| 512Ã—512   | 8          | 64          | ~13GB     | å®‰å…¨è¨­ç½®      |
| 768Ã—768   | 6          | 64          | ~14GB     | é«˜è§£æžåº¦è§’è‰²  |

### SDXLï¼ˆ16GBå„ªåŒ–ï¼‰
| è§£æžåº¦     | Batch Size | Network Dim | VRAM ä½¿ç”¨ | å„ªåŒ–æŠ€è¡“ |
|-----------|------------|-------------|-----------|---------|
| 1024Ã—1024 | 1          | 128         | ~14-15GB  | AdamW8bit + BF16 + Grad Checkpoint |
| 768Ã—768   | 1          | 128         | ~12-13GB  | åŒä¸Šï¼ˆé™ä½Žè§£æžåº¦ï¼‰|
| 1024Ã—1024 | 1          | 128         | ~12-13GB  | åŒä¸Š + Flash Attention 2 |

---

## âš ï¸ é‡è¦é™åˆ¶ï¼ˆRTX 5080ï¼‰

### âŒ çµ•å°ä¸èƒ½ç”¨ï¼š
- `--xformers` æ¨™è¨˜
- `flip_aug = true`ï¼ˆ3D è§’è‰²ï¼‰
- `color_aug = true`ï¼ˆ3D è§’è‰²ï¼‰

### âœ… å¿…é ˆå•Ÿç”¨ï¼š
- `gradient_checkpointing = true`
- `cache_latents_to_disk = true`
- `mixed_precision = "fp16"`

---

## ðŸ”§ å¸¸è¦‹å•é¡Œé€ŸæŸ¥

### è¨“ç·´å¡ä½/æŽ›èµ·
```bash
# æª¢æŸ¥æ•¸æ“šé›†
ls /path/to/images/*.png | wc -l  # æª¢æŸ¥åœ–ç‰‡æ•¸é‡
ls /path/to/images/*.txt | wc -l  # æª¢æŸ¥æ¨™è¨»æ•¸é‡

# é™ä½Ž workers
max_data_loader_n_workers = 0  # æ”¹ç‚º 0 é€²è¡Œé™¤éŒ¯
```

### OOM (è¨˜æ†¶é«”ä¸è¶³)
```toml
# æ–¹æ¡ˆ 1: é™ä½Ž batch size
batch_size = 6  # å¾ž 10 â†’ 6

# æ–¹æ¡ˆ 2: å¢žåŠ æ¢¯åº¦ç´¯ç©
gradient_accumulation_steps = 4  # å¾ž 2 â†’ 4

# æ–¹æ¡ˆ 3: é™ä½Žç¶²çµ¡å®¹é‡
network_dim = 32  # å¾ž 64 â†’ 32
```

### bitsandbytes éŒ¯èª¤
```bash
# ç¢ºä¿ä½¿ç”¨æ­£ç¢ºç’°å¢ƒ
conda activate kohya_ss

# é‡å»ºç’°å¢ƒï¼ˆå¦‚æžœéœ€è¦ï¼‰
bash /mnt/c/AI_LLM_projects/3d-animation-lora-pipeline/setup_kohya_env.sh
```

---

## ðŸ“ æ–‡ä»¶ä½ç½®é€ŸæŸ¥

### é…ç½®ç¯„æœ¬
```
configs/templates/
â”œâ”€â”€ lora_training_template.toml      # ä¸»è¨“ç·´é…ç½®
â””â”€â”€ dataset_config_template.toml     # æ•¸æ“šé›†é…ç½®
```

### ç’°å¢ƒè¨­ç½®
```bash
# è¨­ç½®è…³æœ¬
/mnt/c/AI_LLM_projects/3d-animation-lora-pipeline/setup_kohya_env.sh

# æ¸¬è©¦è…³æœ¬
/mnt/c/AI_LLM_projects/3d-animation-lora-pipeline/test_toml_training.sh
```

### æ–‡æª”
```
docs/
â”œâ”€â”€ KOHYA_TRAINING_GUIDE.md          # å®Œæ•´æŒ‡å—
â”œâ”€â”€ GPU_OPTIMIZATION_GUIDE.md        # GPU å„ªåŒ–
â””â”€â”€ guides/tools/                     # å·¥å…·ä½¿ç”¨æŒ‡å—
```

---

## ðŸŽ¯ å…¸åž‹è¨“ç·´æµç¨‹

### å–®æ¬¡è¨“ç·´ï¼ˆ15 epochsï¼‰
```bash
# 1. æº–å‚™æ•¸æ“šé›†ï¼ˆåœ–ç‰‡ + æ¨™è¨»ï¼‰
/mnt/data/ai_data/datasets/3d-anime/luca/curated_dataset/luca_human/images/
â”œâ”€â”€ img001.png
â”œâ”€â”€ img001.txt
â”œâ”€â”€ img002.png
â”œâ”€â”€ img002.txt
...

# 2. å‰µå»ºé…ç½®ï¼ˆå¾žç¯„æœ¬ï¼‰
configs/luca_human/
â”œâ”€â”€ training_config.toml
â””â”€â”€ dataset_config.toml

# 3. è¨“ç·´
conda activate kohya_ss
python /path/to/sd-scripts/train_network.py \
    --config_file configs/luca_human/training_config.toml

# 4. ç›£æŽ§
nvidia-smi  # æª¢æŸ¥ GPU
tail -f logs/training.log  # æŸ¥çœ‹é€²åº¦
```

### è¿­ä»£è¨“ç·´ï¼ˆè‡ªå‹•å„ªåŒ–ï¼‰
```bash
# ä½¿ç”¨ç¾æœ‰çš„è¿­ä»£è¨“ç·´ç³»çµ±
python scripts/training/launch_iterative_training.py

# æˆ–ä½¿ç”¨ tmuxï¼ˆé•·æ™‚é–“é‹è¡Œï¼‰
bash scripts/training/start_training_tmux.sh
```

---

## ðŸ“ˆ è¨“ç·´å“è³ªåˆ¤æ–·

### å¥½çš„è·¡è±¡ âœ“
- æå¤±ç©©å®šä¸‹é™ï¼ˆ0.25 â†’ 0.15ï¼‰
- GPU ä½¿ç”¨çŽ‡ 80-100%
- è¨“ç·´é€Ÿåº¦ç©©å®šï¼ˆ~30ç§’/æ­¥ï¼‰
- æª¢æŸ¥é»žæ–‡ä»¶æ­£å¸¸ç”Ÿæˆï¼ˆæ¯ 3 epochsï¼‰

### å£žçš„è·¡è±¡ âœ—
- æå¤±éœ‡ç›ªæˆ–ä¸Šå‡
- GPU ä½¿ç”¨çŽ‡ä½Žæ–¼ 50%
- è¨“ç·´é€Ÿåº¦çªç„¶è®Šæ…¢
- OOM éŒ¯èª¤

### èª¿æ•´å»ºè­°
```python
# éŽæ“¬åˆï¼ˆæå¤±å¾ˆä½Žä½†æ•ˆæžœå·®ï¼‰
â†’ æ¸›å°‘ epochs: 15 â†’ 10
â†’ å¢žåŠ æ•¸æ“šé›†æˆ– repeats
â†’ é™ä½Žå­¸ç¿’çŽ‡: 0.0001 â†’ 0.00005

# æ¬ æ“¬åˆï¼ˆæå¤±é«˜ä¸”æ•ˆæžœå·®ï¼‰
â†’ å¢žåŠ  epochs: 15 â†’ 20
â†’ å¢žåŠ ç¶²çµ¡å®¹é‡: dim 64 â†’ 128
â†’ æé«˜å­¸ç¿’çŽ‡: 0.0001 â†’ 0.0002
```

---

## ðŸ”— ç›¸é—œè³‡æº

### å…§éƒ¨æ–‡æª”
- [å®Œæ•´è¨“ç·´æŒ‡å—](docs/KOHYA_TRAINING_GUIDE.md)
- [GPU å„ªåŒ–æŒ‡å—](docs/GPU_OPTIMIZATION_GUIDE.md)
- [é …ç›®ç¸½è¦½](CLAUDE.md)

### ç¯„æœ¬æ–‡ä»¶
- [è¨“ç·´é…ç½®ç¯„æœ¬](configs/templates/lora_training_template.toml)
- [æ•¸æ“šé›†é…ç½®ç¯„æœ¬](configs/templates/dataset_config_template.toml)

### å¤–éƒ¨è³‡æº
- [Kohya SS GitHub](https://github.com/kohya-ss/sd-scripts)
- [LoRA è¨“ç·´æŒ‡å—](https://github.com/kohya-ss/sd-scripts/blob/main/docs/train_network_README-en.md)

---

## ðŸ’¡ å°ˆæ¥­å»ºè­°

1. **ç¸½æ˜¯ä½¿ç”¨ TOML é…ç½®**ï¼ˆä¸è¦ç”¨ CLI åƒæ•¸ï¼‰
2. **ç¸½æ˜¯åœ¨ kohya_ss ç’°å¢ƒä¸­è¨“ç·´**ï¼ˆä¸è¦ç”¨ ai_envï¼‰
3. **ç¸½æ˜¯æ¸¬è©¦ 1 epoch** å†é€²è¡Œå®Œæ•´è¨“ç·´
4. **ç¸½æ˜¯è¨˜éŒ„é…ç½®**ï¼ˆç‰ˆæœ¬æŽ§åˆ¶ TOML æ–‡ä»¶ï¼‰
5. **ç¸½æ˜¯ç›£æŽ§ GPU** ç¢ºä¿é«˜åˆ©ç”¨çŽ‡

---

## ðŸš€ SDXL å¿«é€Ÿè¨“ç·´ï¼ˆ16GB VRAMï¼‰

### å‰ç½®æ¢ä»¶
- âœ… å·²å®Œæˆ SD 1.5 è¨“ç·´ä¸¦æ‰¾åˆ°æœ€ä½³è¶…åƒæ•¸
- âœ… æœ‰ 410 å¼µé«˜å“è³ªcuratedæ•¸æ“šé›†
- âœ… GPU VRAM â‰¥ 16GB

### ä¸€éµå•Ÿå‹•SDXLè¨“ç·´

```bash
# 1. æº–å‚™SDXLæ•¸æ“šé›†ï¼ˆä½¿ç”¨SD 1.5çš„ç›¸åŒåœ–ç‰‡ï¼‰
bash scripts/training/prepare_kohya_dataset.sh \
  --source-dir /mnt/data/ai_data/datasets/3d-anime/luca/luca_final_data \
  --output-dir /mnt/data/ai_data/datasets/3d-anime/luca/luca_sdxl_training \
  --repeat 10 \
  --name luca \
  --validate

# 2. å•Ÿå‹•SDXLè¨“ç·´ï¼ˆè‡ªå‹•è™•ç†æ‰€æœ‰å„ªåŒ–ï¼‰
bash scripts/training/start_sdxl_16gb_training.sh

# 3. ç›£æŽ§VRAMï¼ˆæ–°çµ‚ç«¯ï¼‰
watch -n 1 nvidia-smi

# 4. è¨“ç·´å®Œæˆå¾Œè©•ä¼°
conda run -n ai_env python scripts/evaluation/sota_lora_evaluator.py \
  --evaluate-samples \
  --lora-dir /mnt/data/ai_data/models/lora/luca/sdxl_trial1 \
  --sample-dir /mnt/data/ai_data/models/lora/luca/sdxl_trial1/sample \
  --output-dir /mnt/data/ai_data/models/lora/luca/sdxl_trial1/evaluation
```

### SDXLè¨“ç·´é æœŸ

| é …ç›® | æ•¸å€¼ |
|------|------|
| **è¨“ç·´æ™‚é–“** | 5-6 å°æ™‚ |
| **VRAMå³°å€¼** | 14-15GB |
| **Checkpoints** | 10 å€‹ï¼ˆæ¯ 2 epochsï¼‰ |
| **è¦–è¦ºæ”¹å–„** | +40% é¢éƒ¨ç´°ç¯€, +35% å…‰å½± |

### é—œéµå„ªåŒ–æŠ€è¡“ï¼ˆå·²å…§å»ºåœ¨è…³æœ¬ä¸­ï¼‰

1. **AdamW8bit** - çœ40% VRAM
2. **Gradient Checkpointing** - çœ30% VRAM
3. **BF16 Mixed Precision** - çœ25% VRAM
4. **Latent Caching** - çœ2GB VRAM

### OOMæ•…éšœæŽ’é™¤

å¦‚æžœé‡åˆ° Out of Memoryï¼š

```bash
# æ–¹æ³•1: é™ä½Žè§£æžåº¦ï¼ˆä¿®æ”¹configs/training/sdxl_16gb_optimized.tomlï¼‰
resolution = "768,768"  # å¾ž1024é™åˆ°768

# æ–¹æ³•2: å‡çµtext encoder
train_text_encoder = false  # çœç´„2GB VRAM
```

### å®Œæ•´SDXLæ–‡æª”

è©³ç´°èªªæ˜Žè¦‹ï¼š`docs/guides/SDXL_16GB_TRAINING_GUIDE.md`

---

## ðŸ§ª LoRA å“è³ªæ¸¬è©¦ï¼ˆè¨“ç·´å¾Œå¿…åšï¼‰

### å¿«é€Ÿå•Ÿå‹•æ¸¬è©¦
```bash
# ä¸€éµæ¸¬è©¦ Trial 3.5 æœ€ä½³æª¢æŸ¥é»ž
bash scripts/evaluation/test_trial35_lora.sh
```

### å…¨é¢æ¸¬è©¦ï¼ˆæŽ¨è–¦ï¼‰
```bash
# æ¸¬è©¦ä»»ä½• LoRA checkpoint
python scripts/evaluation/comprehensive_lora_test.py \
    /path/to/lora.safetensors \
    --base-model runwayml/stable-diffusion-v1-5 \
    --seeds 3 \
    --steps 30 \
    --cfg-scale 7.5

# è¼¸å‡ºï¼š
# - outputs/lora_testing/*/TEST_REPORT.md  # è©³ç´°å“è³ªå ±å‘Š
# - outputs/lora_testing/*/grids/         # æ¯”è¼ƒç¶²æ ¼åœ–
# - outputs/lora_testing/*/images/        # æ¸¬è©¦åœ–ç‰‡ï¼ˆæŒ‰é¡žåˆ¥ï¼‰
```

### æ¸¬è©¦é¡žåˆ¥ï¼ˆè‡ªå‹•åŸ·è¡Œ9å¤§é¡žï¼Œæ¯é¡ž5å€‹prompts Ã— 3å€‹seeds = 135å¼µåœ–ï¼‰
1. **Portraits** - è‚–åƒç‰¹å¯«ï¼ˆå„ç¨®è¡¨æƒ…ï¼‰
2. **Full Body** - å…¨èº«å§¿å‹¢èˆ‡æ§‹åœ–
3. **Angles** - ä¸åŒè¦–è§’ï¼ˆæ­£é¢/å´é¢/å››åˆ†ä¹‹ä¸‰ï¼‰
4. **Environments** - å„ç¨®èƒŒæ™¯å ´æ™¯
5. **Expressions** - æƒ…æ„Ÿè¡¨é”ï¼ˆé–‹å¿ƒ/é©šè¨/æ€è€ƒï¼‰
6. **Actions** - å‹•æ…‹å‹•ä½œï¼ˆæ®æ‰‹/æŒ‡å‘/ç«™ç«‹ï¼‰
7. **Clothing** - æœè£è®ŠåŒ–
8. **Lighting** - å…‰ç…§æ¢ä»¶ï¼ˆæˆ²åŠ‡æ€§/æŸ”å’Œ/æ˜Žäº®ï¼‰
9. **Compositions** - ç•«é¢æ§‹åœ–ï¼ˆä¸­æ™¯/ç‰¹å¯«/å»£è§’ï¼‰

### å“è³ªæª¢æŸ¥æ¸…å–®
```
âœ… è§’è‰²èº«ä»½ç©©å®šï¼ˆæ‰€æœ‰åœ–ç‰‡è­˜åˆ¥ä¸€è‡´ï¼‰
âœ… æç¤ºè©žéµå¾ªåº¦ï¼ˆæº–ç¢ºåŸ·è¡ŒæŒ‡ä»¤ï¼‰
âœ… ç„¡è§£å‰–éŒ¯èª¤æˆ–å½å½±
âœ… ä¿æŒPixar 3Dé¢¨æ ¼ï¼ˆå¹³æ»‘é™°å½±ã€PBRæè³ªï¼‰
âœ… é¢éƒ¨ç‰¹å¾µæº–ç¢ºç©©å®š
âœ… å…‰ç…§å’Œé™°å½±é©ç•¶
âœ… ç„¡éŽæ“¬åˆè·¡è±¡ï¼ˆä¸éŽæ–¼é¡žä¼¼è¨“ç·´æ•¸æ“šï¼‰
âœ… èƒ½è™•ç†å¤šç¨®è§’åº¦å’Œå§¿å‹¢
âœ… èƒŒæ™¯/ç’°å¢ƒæ¸²æŸ“å¯æŽ¥å—
âœ… æ•´é«”å“è³ªé”åˆ°ç”Ÿç”¢æ¨™æº–
```

### æ¸¬è©¦åƒæ•¸å„ªåŒ–
| ç”¨é€” | Seeds | Steps | CFG | ç¸½åœ–æ•¸ | æ™‚é–“ (RTX 3090) |
|-----|-------|-------|-----|-------|----------------|
| **å¿«é€Ÿæ¸¬è©¦** | 1 | 20 | 7.0 | 45å¼µ | ~5åˆ†é˜ |
| **æ¨™æº–æ¸¬è©¦** | 3 | 30 | 7.5 | 135å¼µ | ~15åˆ†é˜ |
| **é«˜å“è³ªæ¸¬è©¦** | 5 | 50 | 7.5 | 225å¼µ | ~30åˆ†é˜ |

### ä¸‹ä¸€æ­¥æ±ºç­–
```bash
# âœ… å¦‚æžœæ¸¬è©¦é€šéŽ â†’ é€²å…¥SDXLè¨“ç·´
bash scripts/training/start_sdxl_16gb_training.sh

# âŒ å¦‚æžœæ¸¬è©¦å¤±æ•— â†’ æª¢æŸ¥å•é¡Œä¸¦èª¿æ•´
# å¸¸è¦‹å•é¡Œï¼š
# - éŽæ“¬åˆ â†’ æ¸›å°‘epochsæˆ–å¢žåŠ æ•¸æ“š
# - æ¬ æ“¬åˆ â†’ å¢žåŠ epochsæˆ–èª¿é«˜å­¸ç¿’çŽ‡
# - ä¸ç©©å®š â†’ æª¢æŸ¥æ•¸æ“šé›†å“è³ª
```

---

## ðŸ“Œ æŽ¨è–¦Workflow

```
âœ… éšŽæ®µ1: SD 1.5è¨“ç·´ï¼ˆTrial 3.5ï¼‰
   â””â”€ æ™‚é–“: ~2.2å°æ™‚
   â””â”€ ç›®æ¨™: é©—è­‰è¶…åƒæ•¸å’Œæ•¸æ“šé›†å“è³ª

âœ… éšŽæ®µ2: å…¨é¢å“è³ªæ¸¬è©¦ â­ **NEW**
   â””â”€ æ™‚é–“: ~15åˆ†é˜
   â””â”€ ç›®æ¨™: ç”Ÿæˆ135å¼µæ¸¬è©¦åœ–ï¼ˆ9é¡žÃ—5promptsÃ—3seedsï¼‰
   â””â”€ å·¥å…·: comprehensive_lora_test.py
   â””â”€ å‘½ä»¤: bash scripts/evaluation/test_trial35_lora.sh

âœ… éšŽæ®µ3: è©•ä¼°æ¸¬è©¦çµæžœ
   â””â”€ æ™‚é–“: ~10åˆ†é˜
   â””â”€ ç›®æ¨™: æª¢æŸ¥å“è³ªæ¸…å–®ï¼Œç¢ºèªç„¡éŽæ“¬åˆ/æ¬ æ“¬åˆ

âœ… éšŽæ®µ4: SDXLè¨“ç·´ï¼ˆå¦‚éœ€æ›´é«˜å“è³ªï¼‰
   â””â”€ æ™‚é–“: ~5-6å°æ™‚
   â””â”€ ç›®æ¨™: 2å€è§£æžåº¦ + é¡¯è‘—è¦–è¦ºæ”¹å–„

âœ… éšŽæ®µ5: æœ€çµ‚å°æ¯”é¸æ“‡
   â””â”€ æ™‚é–“: ~20åˆ†é˜
   â””â”€ ç›®æ¨™: æ ¹æ“šéœ€æ±‚é¸æ“‡SD 1.5æˆ–SDXL
```

---

## ðŸ”— ç›¸é—œè³‡æº

### ä¸»è¦æŒ‡å—
- [Lucaå®Œæ•´è¨“ç·´æŒ‡å—](docs/guides/LUCA_TRAINING_GUIDE.md) - åŒ…å«SD 1.5å’ŒSDXL
- [SDXL 16GBè¨“ç·´å®Œæ•´æ–‡æª”](docs/guides/SDXL_16GB_TRAINING_GUIDE.md)
- [æ›¿ä»£æ¨¡åž‹å®Œæ•´æŒ‡å—](docs/guides/ALTERNATIVE_MODELS_FOR_PIXAR_STYLE.md) - â­ **NEW** FLUX.1, SD 3.5, Hunyuanç­‰
- [GPUå„ªåŒ–æŒ‡å—](docs/GPU_OPTIMIZATION_GUIDE.md)

### é…ç½®æ–‡ä»¶
- SD 1.5: `configs/training/luca_trial35.toml`
- SDXL: `configs/training/sdxl_16gb_optimized.toml`

---

**æœ€å¾Œæ›´æ–°ï¼š** 2025-11-15 (v1.2 - æ–°å¢žLoRAå“è³ªæ¸¬è©¦ç³»çµ±)
**ç’°å¢ƒï¼š** `kohya_ss` (PyTorch 2.7.1+cu128, bitsandbytes 0.48.2)
**ç¡¬é«”ï¼š** RTX 5080 16GB
**æ”¯æ´æ¨¡åž‹ï¼š** SD 1.5 + SDXL (16GBå„ªåŒ–)
