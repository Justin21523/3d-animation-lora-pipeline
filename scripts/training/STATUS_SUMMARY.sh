#!/bin/bash
# Training Pipeline Status Summary
# DO NOT PUT IN /tmp - This is a project script

echo "========================================="
echo "LUCA LORA PIPELINE - STATUS SUMMARY"
echo "========================================="
echo ""

# Caption Generation Status
echo "1. CAPTION GENERATION"
if tmux has-session -t caption_luca 2>/dev/null; then
    echo "   Status: ‚úì Running (tmux: caption_luca)"
    CAPTIONS=$(find /mnt/data/ai_data/datasets/3d-anime/luca/curated_dataset_v2_smart/luca_human/captions -name "*.txt" 2>/dev/null | wc -l)
    echo "   Progress: $CAPTIONS / 372 ($((CAPTIONS*100/372))%)"
    REMAINING=$((372-CAPTIONS))
    echo "   Remaining: $REMAINING captions"
else
    echo "   Status: Not running"
fi
echo "   Monitor: bash /tmp/monitor_caption.sh"
echo "   Attach: tmux attach -t caption_luca"
echo ""

# Training Environment
echo "2. TRAINING ENVIRONMENT"
echo "   ‚úì ai_env: Caption generation (Qwen2-VL)"
echo "   ‚úì kohya_ss: LoRA training (Kohya SS sd-scripts)"
echo "   ‚úì sd-scripts: /mnt/c/AI_LLM_projects/ai_warehouse/sd-scripts"
echo "   ‚úì Base model: v1-5-pruned-emaonly.safetensors (4GB)"
echo "   ‚úì NumPy: 1.26.4 (kohya_ss env fixed)"
echo ""

# Training Configuration
echo "3. TRAINING CONFIGURATION"
echo "   ‚úì Config: configs/training/luca_human.toml"
echo "   ‚úì Based on: docs/training_optimization/ research"
echo "   ‚úì Optimizations:"
echo "      - Learning rate: 8e-5 (Èò≤Ê≠¢ÁâπÂæµÊºÇÁßª)"
echo "      - Text Encoder LR: 6e-5 (Âä†Âº∑Ë∫´‰ªΩÂ≠∏Áøí)"
echo "      - Network dim: 96 (3DËßíËâ≤ÊúÄ‰Ω≥ÔºåÂõ∫ÂÆö‰∏çÂ¢ûÈï∑)"
echo "      - Epochs: 10 (Èò≤Ê≠¢ÈÅéÂ∫¶Ë®ìÁ∑¥)"
echo "      - Batch size: 8 (effective: 16 with gradient_accumulation)"
echo "   ‚úì RTX 5080: NO xformers, AdamW optimizer"
echo ""

# Dataset
echo "4. DATASET"
IMAGE_COUNT=$(find /mnt/data/ai_data/datasets/3d-anime/luca/curated_dataset_v2_smart/luca_human/images -name "*.png" 2>/dev/null | wc -l)
CAPTION_COUNT=$(find /mnt/data/ai_data/datasets/3d-anime/luca/curated_dataset_v2_smart/luca_human/captions -name "*.txt" 2>/dev/null | wc -l)
echo "   Images: $IMAGE_COUNT"
echo "   Captions: $CAPTION_COUNT"
if [ "$CAPTION_COUNT" -ge "$IMAGE_COUNT" ]; then
    echo "   Status: ‚úì Complete"
else
    echo "   Status: ‚è≥ In progress ($((IMAGE_COUNT-CAPTION_COUNT)) remaining)"
fi
echo ""

# Next Steps
echo "5. NEXT STEPS"
if [ "$CAPTION_COUNT" -lt "$IMAGE_COUNT" ]; then
    echo "   ‚è≥ Wait for caption generation ($CAPTION_COUNT/$IMAGE_COUNT)"
    echo "   ‚è±Ô∏è  Est. time: ~$((((IMAGE_COUNT-CAPTION_COUNT))/2)) min"
else
    echo "   ‚úÖ Ready to train!"
    echo "   üöÄ Command:"
    echo "      bash scripts/generic/training/launch_lora_training.sh \\"
    echo "        --config configs/training/luca_human.toml \\"
    echo "        --tmux lora_luca"
fi
echo ""
echo "========================================="
