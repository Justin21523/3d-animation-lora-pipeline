#!/bin/bash
# è¨˜æ†¶é«”å®‰å…¨çš„è‡ªå‹•åŒ–è¨“ç·´è…³æœ¬

set -e

CHARACTERS=(2 3 4 5 6 7)
BASE_MODEL="/mnt/c/AI_LLM_projects/ai_warehouse/models/stable-diffusion/checkpoints/anything-v5-PrtRE.safetensors"
EVAL_DIR="/mnt/data/ai_data/lora_evaluation"

# æ¸…ç†è¨˜æ†¶é«”å‡½æ•¸
cleanup_memory() {
    echo "ðŸ§¹ æ¸…ç†è¨˜æ†¶é«”..."
    pkill -f train_network.py 2>/dev/null || true
    pkill -f evaluate_lora.py 2>/dev/null || true
    sleep 5
    sync
    echo "âœ“ è¨˜æ†¶é«”æ¸…ç†å®Œæˆ"
}

# æª¢æŸ¥è¨˜æ†¶é«”å‡½æ•¸
check_memory() {
    AVAILABLE=$(free -g | awk '/^Mem:/{print $7}')
    echo "ðŸ“Š å¯ç”¨è¨˜æ†¶é«”: ${AVAILABLE}GB"
    if [ "$AVAILABLE" -lt 10 ]; then
        echo "âš ï¸  è¨˜æ†¶é«”ä¸è¶³ï¼Œç­‰å¾…é‡‹æ”¾..."
        cleanup_memory
        sleep 10
    fi
}

echo "=============================================="
echo "  ðŸš€ è¨˜æ†¶é«”å®‰å…¨çš„è‡ªå‹•åŒ–LoRAè¨“ç·´æµç¨‹"
echo "=============================================="
echo "é–‹å§‹æ™‚é–“: $(date)"
echo ""

for char_num in "${CHARACTERS[@]}"; do
    echo ""
    echo "======================================================================"
    echo "  ðŸ“Œ Character${char_num} é–‹å§‹"
    echo "======================================================================"

    # è¨“ç·´å‰æ¸…ç†å’Œæª¢æŸ¥
    cleanup_memory
    check_memory

    # è¨“ç·´
    echo "â° $(date '+%H:%M:%S') - é–‹å§‹è¨“ç·´ Character${char_num}..."

    conda run -n ai_env python sd-scripts/train_network.py \
        --config_file configs/character_loras/character${char_num}_config_optimized.toml \
        > /tmp/character${char_num}_training.log 2>&1

    if [ $? -eq 0 ]; then
        echo "âœ… $(date '+%H:%M:%S') - Character${char_num} è¨“ç·´å®Œæˆ"
    else
        echo "âŒ $(date '+%H:%M:%S') - Character${char_num} è¨“ç·´å¤±æ•—ï¼"
        echo "éŒ¯èª¤æ—¥èªŒï¼š"
        tail -30 /tmp/character${char_num}_training.log
        cleanup_memory
        continue
    fi

    # è¨“ç·´å¾Œæ¸…ç†
    cleanup_memory
    echo "â³ ç­‰å¾…GPUå’Œè¨˜æ†¶é«”å†·å» (15ç§’)..."
    sleep 15

    # æ¸¬è©¦
    echo "ðŸ§ª $(date '+%H:%M:%S') - é–‹å§‹æ¸¬è©¦ Character${char_num}..."

    LORA_PATH="/mnt/data/ai_data/models/lora/yokai_characters/character${char_num}/yokai_character${char_num}_lora.safetensors"
    OUTPUT_DIR="${EVAL_DIR}/character${char_num}_$(date +%Y%m%d_%H%M%S)"

    if [ -f "$LORA_PATH" ]; then
        conda run -n ai_env python scripts/evaluate_lora.py \
            "$LORA_PATH" \
            --base_model "$BASE_MODEL" \
            --output_dir "$OUTPUT_DIR" \
            --num_samples 8 \
            --seed 42 \
            > /tmp/character${char_num}_eval.log 2>&1

        if [ $? -eq 0 ]; then
            echo "âœ… $(date '+%H:%M:%S') - Character${char_num} æ¸¬è©¦å®Œæˆ"
            echo "   æ¸¬è©¦åœ–ç‰‡: $OUTPUT_DIR"
        else
            echo "âš ï¸  $(date '+%H:%M:%S') - Character${char_num} æ¸¬è©¦å¤±æ•—ï¼ˆä¸å½±éŸ¿å¾ŒçºŒè¨“ç·´ï¼‰"
        fi
    else
        echo "âš ï¸  æ‰¾ä¸åˆ°LoRAæª”æ¡ˆ: $LORA_PATH"
    fi

    # æ¸¬è©¦å¾Œæ¸…ç†
    cleanup_memory

    echo "======================================================================"
    echo "  âœ… Character${char_num} å®Œæˆ"
    echo "======================================================================"
    echo ""
done

echo ""
echo "=============================================="
echo "  ðŸŽ‰ æ‰€æœ‰è§’è‰²è¨“ç·´å’Œæ¸¬è©¦å®Œæˆï¼"
echo "=============================================="
echo "çµæŸæ™‚é–“: $(date)"
echo ""
echo "ç”Ÿæˆçš„æ¨¡åž‹ï¼š"
ls -lh /mnt/data/ai_data/models/lora/yokai_characters/character*/yokai_character*_lora.safetensors 2>/dev/null
